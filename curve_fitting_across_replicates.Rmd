---
title: "Curve fitting and hypothesis testing across replicates"
author: "Dorothee Childs"
date: "01/12/2017"
output: BiocStyle::html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Preparation
```{r, warning=FALSE}
suppressPackageStartupMessages({
  # Load the necessary Bioconductor packages.
  # For help regarding their installation, please visit the Bioconductor websites. 
  require("TPP")
  require("BiocStyle")
  require("biobroom")
  # load the tidyverse package. 
  # It will automatically load the packages 'ggplot2', 'tidyr' and 'dplyr',
  # which we use for modelling, data manipulation and plotting in this script:
  require("tidyverse")
})

# Set the path where we want the TPP package results to be stored:
dir_out <- getwd()
```

# Import and normalize with the `TPP` package

The following command will load two objects containing the data and the config table for a small TPP-TR example dataset from the `TPP` package. You can find further details about these objects, and how they are used to start the package, in the `TPP` package vignette.
```{r}
data("hdacTR_smallExample")
```

We first import and normalize the data with the `TPP` package functions `tpptrImport` and `tpptrNormalize`: 
```{r, message=FALSE}
tppData <- TPP::tpptrImport(configTable = hdacTR_config, 
                            data = hdacTR_data, idVar = "gene_name", fcStr = "rel_fc_", 
                            qualColName = "qupm") 

tppDataNormalized <- TPP::tpptrNormalize(data = tppData)$normData
```
# Load package results and convert to long tables:

The object `tppDataNormalized` that we created in the previous Section contains a list of `ExpressionSets` with the normalized fold changes from each experiment.
For downstream analysis, we convert them into long tables using the Bioconductor package `Biobroom`. The subsequent modelling steps can easily be implemented with help of the `dplyr` and `tidyr` packages once our data is in this format.

```{r tidy_eSets}
# Convert each ExpressionSet to a long table:
tidyData <- lapply(tppDataNormalized, function(d) biobroom::tidy.ExpressionSet(d, addPheno = TRUE))

# Concatenate long tables:
tidyData <- bind_rows(tidyData, .id = "Experiment") %>%
  dplyr::rename(foldChange = value) %>%
  #left_join(distinct(hdacTR_config, Experiment, Condition)) %>%
  separate(Experiment, into = c("Condition", "Replicate"), sep = "_", remove = FALSE)
```


# Fit melting curves across replicates

Now we fit the melting curves for each protein and condition. We use the same equation as described by Savitski et al. (2014), Science, 346(6205):
```{r fit_curves, warning=FALSE}
model <- as.formula("y ~ (1 - Pl) * 1/(1 + exp(-(a/x - b))) + Pl")

modelFits <- tidyData %>%
  group_by(gene, Condition) %>%
  do(fittedModel = try(nls(formula=model, 
                           start=c(Pl = 0, a = 550, b = 10), 
                           data=list(x = .$temperature, y = .$foldChange),
                           na.action=na.exclude, 
                           algorithm="port",
                           lower = c(0.0, 1e-5, 1e-5), 
                           upper = c(1.5, 15000, 250),
                           control = nls.control(maxiter=50, warnOnly = TRUE)),
                       silent = TRUE))
```

# Predict models
For visualization purposes, the predicted curves can be generated by the following command:
```{r predict_models}
# Create a dense grid of x values to make curves appear less `step-wise` on the final plots:
temperatures = seq(min(tidyData$temperature), max(tidyData$temperature), length.out = 100)

# Compute predictions for each value on the grid
modelPredictions <- modelFits %>% 
  ungroup %>%
  group_by(gene, Condition) %>%
  do(data.frame(temperature = temperatures, 
                prediction = predict(object = .$fittedModel[[1]], 
                                     newdata = list(x = temperatures))))
```
We have now predicted 100 values within the measured temperature range for each model.

# Plot predictions
Let's select two proteins, HDAC1 and HDAC2:
```{r}
hdacTargetIDs <- c("HDAC1", "HDAC2")

hdacData <- filter(tidyData, gene %in% hdacTargetIDs)

hdacPredictions <- filter(modelPredictions, gene %in% hdacTargetIDs)
```

Let's first create a plot that contains the fold changes per protein and temperature:
```{r}
# Create plot objects in ggplot2 format:
plt <- ggplot(hdacData, aes(x = temperature, y = foldChange, color = Condition))

# Add measurements:
plt <- plt +
  geom_point(aes(shape = factor(Replicate))) +
  facet_grid(. ~ gene)

# Add predictions per condition:
plt <- plt +
  geom_line(data = hdacPredictions, aes(y = prediction))
```

We have now created plots for each protein that display the measurements and the fitted melting curves. They are stored in an object of class `ggplot` and can be customized to suit your needs.

For example, you can change the theme and colors in the following way:
```{r}
plt_customized <- plt +
  scale_color_manual(values = c(Panobinostat = "darkred", Vehicle = "steelblue")) +
  theme_bw()

plt_customized
```




# Hypothesis testing
Hypothesis testing on melting point (Tm) shifts can be performed by a Wald test. For this, we compute the estimated Tm-shift and its standard error.

## Compute Tm-shifs per protein
First, we define a function to obtain the Tm shift and its estimated standard error:

```{r function_eval_meltCurve}
obtain_meltCurve_pars <- function(model){
  tm = a = b = pl = tm_sd <- NA
  if (class(model) != "try-error"){
    
    # Extract model parameters:
    pars <- coefficients(model)
    a <- pars[["a"]]
    b <- pars[["b"]]
    pl <- pars[["Pl"]]
    
    # Compute melting point (Tm):
    tm_fct <- parse(text = "a / (b - log((1-pl)/(1/2 - pl) - 1))")
    suppressWarnings(tm <- eval(tm_fct))
    
    # Compute derivatives of Tm with respect to each parameter:
    dtm_da <-D(tm_fct, "a")
    dtm_db <-D(tm_fct, "b")
    dtm_dpl <-D(tm_fct, "pl")
    grad_tm <- c(a = eval(dtm_da), b = eval(dtm_db), pl = eval(dtm_dpl))
    
    # Compute covariance matrix and estimator variance:
    covmat <- try(vcov(model), silent = TRUE)
    if (!inherits(covmat, "try-error")){
      var_tm <- grad_tm %*% covmat[c("a", "b", "Pl"), c("a", "b", "Pl")] %*% grad_tm
      tm_sd <- as.numeric(sqrt(var_tm))
    }
  }
  return(data.frame(tm = tm, a = a,  b = b,  pl = pl, tm_sd = tm_sd))
}
```

We use this function to compute Tm values for each protein and condition:
```{r compute_Tm, warning=FALSE}
modelParams <- modelFits %>%
  group_by(gene, Condition) %>%
  do(obtain_meltCurve_pars(model = .$fittedModel[[1]]))
```

Next, we combine the condition-specific estimates to obtain the Tm shift per protein:
```{r compute_dTm}
tmShifts <- modelParams %>%
  group_by(gene) %>%
  summarize(dTm = sum(tm * c(1,-1)),
            dTm_sd = sqrt(sum(tm_sd^2)))
```


## Compute p-values and Fdr

We can compute Wald test p-values by comparing the scaled estimator to the standard normal distribution:
```{r compute_p_vals}
testResults <- tmShifts %>%
  mutate(waldStat = dTm / dTm_sd,
         pValue = 2 * pnorm(-abs(waldStat)),
         pAdj = p.adjust(pValue, method = "fdr")) 
```

These results can be used, for example, to compute volcano plots, enrichment analyses, or other types of downstream analyses.

We hope this little tutorial could help you to fit models with customized groupings to the TPP-TR package output. Please don't hesitate to contact the Bioconductor support site (https://support.bioconductor.org/) for further questions.

